{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "vscode": {
     "languageId": "scala"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark import SparkContext, SparkConf\n",
    "cf = SparkConf()\n",
    "cf.set(\"spark.submit.deployMode\",\"client\")\n",
    "sc = SparkContext.getOrCreate(cf)\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession \\\n",
    "\t    .builder \\\n",
    "\t    .appName(\"Python Spark SQL basic example\") \\\n",
    "\t    .config(\"spark.some.config.option\", \"some-value\") \\\n",
    "\t    .getOrCreate()\n",
    "                      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning: Legally_Operating_Businesses_copy.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start by reading in 'Legally_Operating_Businesses_copy.csv' as a pandas data frame. We are going to be looking at the years and months, so it is important to change the datatypes of the date column to a datetime datatype. We will also change the datatypes of license status column, industry column, address state column, and address zip column to string. This is so that all of the entries in this column are uniform. I will also modify the column names from words separated by spaces to words separated by underscores. For example 'Address State' will be renamed 'Address_State'. We are only modifying certain columns because we are only interested in these columns of the dataset. All of this is done, so to make it easier to not only convert the dataframe into a pyspark dataframe, but also to make it easier to use SQL queries on the soon to be created pyspark dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "vscode": {
     "languageId": "scala"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kzhen\\AppData\\Local\\Temp\\ipykernel_34424\\1627217964.py:5: DtypeWarning: Columns (19,20) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  business_license = pd.read_csv('data/Legally_Operating_Businesses_copy.csv', na_values = \"not available\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "License_Creation_Date    datetime64[ns]\n",
       "License_Status                   string\n",
       "Industry                         string\n",
       "Address_State                    string\n",
       "Address_ZIP                      string\n",
       "dtype: object"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "#read dataset in pandas\n",
    "#set null values as a string, to make all the columns the same data type - makes it easier to convert to spark data frame\n",
    "business_license = pd.read_csv('data/Legally_Operating_Businesses_copy.csv', na_values = \"not available\")\n",
    "\n",
    "#set respective columns to its designated datatype\n",
    "business_license['License Creation Date'] = pd.to_datetime(business_license['License Creation Date']) \n",
    "business_license = business_license.astype({'License Status':'string','Industry':'string', 'Address State':'string', 'Address ZIP':'string' })\n",
    "\n",
    "#rename each column name from separate words to words separated by underscores\n",
    "business_license = business_license.loc[:, [\"License Creation Date\", \"License Status\", \"Industry\", \"Address State\", \"Address ZIP\"]] \n",
    "business_license.rename(columns={\"License Creation Date\": \"License_Creation_Date\", \"License Status\": \"License_Status\", \"Address State\":\"Address_State\", \"Address ZIP\": \"Address_ZIP\"}, inplace=True)\n",
    "\n",
    "business_license.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    "Read the business_license pandas dataframe into a spark dataframe, This way we can now use Pyspark SQL queries to further work on the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "vscode": {
     "languageId": "scala"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+--------------+--------------------+----------------+-----------+\n",
      "|License_Creation_Date|License_Status|            Industry|   Address_State|Address_ZIP|\n",
      "+---------------------+--------------+--------------------+----------------+-----------+\n",
      "|           2010-02-04|      Inactive|Home Improvement ...|              NJ|      07726|\n",
      "|           2022-01-11|        Active|   Sightseeing Guide|              NY|      11214|\n",
      "|           2017-10-31|        Active|   Sightseeing Guide|              NY|      10028|\n",
      "|           2022-04-22|        Active|      Pedicab Driver|              NY|      11214|\n",
      "|           2018-09-11|        Active|   Sightseeing Guide|British Columbia|      V6Z1C|\n",
      "|           2017-09-01|      Inactive|Home Improvement ...|              PA|      19013|\n",
      "|           2011-12-21|      Inactive|    Tow Truck Driver|              NY|      10302|\n",
      "|           2015-04-20|      Inactive|Home Improvement ...|              NY|      11793|\n",
      "|           2000-05-23|        Active|   Sightseeing Guide|              NY|      10023|\n",
      "|           2015-10-29|      Inactive|    Tow Truck Driver|              NY|      10460|\n",
      "|           2022-07-15|        Active|       Ticket Seller|              NY|      10454|\n",
      "|           2014-04-10|      Inactive|          Auctioneer|              NY|      11354|\n",
      "|           2011-03-02|      Inactive|    Tow Truck Driver|              NY|      10452|\n",
      "|           2019-05-14|        Active|       Ticket Seller|              NY|      10304|\n",
      "|           2012-02-13|      Inactive|      General Vendor|              NY|      11422|\n",
      "|           2001-01-23|      Inactive|Home Improvement ...|              NY|      11710|\n",
      "|           2017-03-23|        Active|       Ticket Seller|              NY|      11435|\n",
      "|           2013-04-19|      Inactive|      Pedicab Driver|              NY|      11510|\n",
      "|           2014-04-15|      Inactive|    Tow Truck Driver|              NY|      10314|\n",
      "|           2018-12-19|      Inactive|Home Improvement ...|              NY|      10010|\n",
      "+---------------------+--------------+--------------------+----------------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import *\n",
    "#create schema for your dataframe\n",
    "schema = StructType([StructField(\"License_Creation_Date\", DateType(), True)\\\n",
    "                   ,StructField(\"License_Status\",StringType(), True)\\\n",
    "                   ,StructField(\"Industry\", StringType(), True)\\\n",
    "                   ,StructField(\"Address_State\", StringType(), True)\\\n",
    "                   ,StructField(\"Address_ZIP\", StringType(), True)])\n",
    "\n",
    "#create spark dataframe using schema\n",
    "business_license_df = spark.createDataFrame(business_license,schema=schema)\n",
    "business_license_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see not all of the licenses are from New York, so I want to remove the entries of the table that are not businesses from NY. Also we are only focused on New York City, so we will only keep entries that are in the five boroughs (Queens, Manhattan/New York, Brooklyn, Bronx, Staten Island)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "vscode": {
     "languageId": "scala"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+--------------+--------------------+-------------+-----------+\n",
      "|License_Creation_Date|License_Status|            Industry|Address_State|Address_ZIP|\n",
      "+---------------------+--------------+--------------------+-------------+-----------+\n",
      "|           2022-01-11|        Active|   Sightseeing Guide|           NY|      11214|\n",
      "|           2017-10-31|        Active|   Sightseeing Guide|           NY|      10028|\n",
      "|           2022-04-22|        Active|      Pedicab Driver|           NY|      11214|\n",
      "|           2011-12-21|      Inactive|    Tow Truck Driver|           NY|      10302|\n",
      "|           2015-04-20|      Inactive|Home Improvement ...|           NY|      11793|\n",
      "|           2000-05-23|        Active|   Sightseeing Guide|           NY|      10023|\n",
      "|           2015-10-29|      Inactive|    Tow Truck Driver|           NY|      10460|\n",
      "|           2022-07-15|        Active|       Ticket Seller|           NY|      10454|\n",
      "|           2014-04-10|      Inactive|          Auctioneer|           NY|      11354|\n",
      "|           2011-03-02|      Inactive|    Tow Truck Driver|           NY|      10452|\n",
      "|           2019-05-14|        Active|       Ticket Seller|           NY|      10304|\n",
      "|           2012-02-13|      Inactive|      General Vendor|           NY|      11422|\n",
      "|           2001-01-23|      Inactive|Home Improvement ...|           NY|      11710|\n",
      "|           2017-03-23|        Active|       Ticket Seller|           NY|      11435|\n",
      "|           2013-04-19|      Inactive|      Pedicab Driver|           NY|      11510|\n",
      "|           2014-04-15|      Inactive|    Tow Truck Driver|           NY|      10314|\n",
      "|           2018-12-19|      Inactive|Home Improvement ...|           NY|      10010|\n",
      "|           2018-07-05|        Active|           Locksmith|           NY|      10128|\n",
      "|           1997-04-08|      Inactive|              Garage|           NY|      11372|\n",
      "|           2001-04-02|      Inactive|Tobacco Retail De...|           NY|      11226|\n",
      "+---------------------+--------------+--------------------+-------------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#remove non NY entries\n",
    "business_license_df = business_license_df.filter(business_license_df[\"Address_State\"] == \"NY\")\n",
    "business_license_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will filter for businesses that have a NYC zip code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#aggregate dictionary of zip codes mapped to NYC boroughs\n",
    "zips = {}\n",
    "with open(\"zipcodes.txt\") as f:\n",
    "    for line in f:\n",
    "        #each line has two zips matched to borough\n",
    "        line = line.strip().split()\n",
    "        for i in range(0,len(line),2):\n",
    "            zips[line[i]] = line[i+1]\n",
    "            \n",
    "zips_lst = list(zips.keys())\n",
    "\n",
    "#fetch all zip codes associated with borough\n",
    "def borough_zips(zips, borough):\n",
    "    lst = [key for key,value in zips.items() if value == borough]\n",
    "    return lst\n",
    "\n",
    "#zip codes by borough\n",
    "manhattan_zips = borough_zips(zips, \"Manhattan\")\n",
    "brooklyn_zips= borough_zips(zips, \"Brooklyn\")\n",
    "queen_zips = borough_zips(zips, \"Queens\")\n",
    "bronx_zips = borough_zips(zips, \"Bronx\")\n",
    "statenisland_zips = borough_zips(zips, \"Staten\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "vscode": {
     "languageId": "scala"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+--------------+--------------------+-------------+-----------+\n",
      "|License_Creation_Date|License_Status|            Industry|Address_State|Address_ZIP|\n",
      "+---------------------+--------------+--------------------+-------------+-----------+\n",
      "|           2022-01-11|        Active|   Sightseeing Guide|           NY|      11214|\n",
      "|           2017-10-31|        Active|   Sightseeing Guide|           NY|      10028|\n",
      "|           2022-04-22|        Active|      Pedicab Driver|           NY|      11214|\n",
      "|           2011-12-21|      Inactive|    Tow Truck Driver|           NY|      10302|\n",
      "|           2000-05-23|        Active|   Sightseeing Guide|           NY|      10023|\n",
      "|           2015-10-29|      Inactive|    Tow Truck Driver|           NY|      10460|\n",
      "|           2022-07-15|        Active|       Ticket Seller|           NY|      10454|\n",
      "|           2014-04-10|      Inactive|          Auctioneer|           NY|      11354|\n",
      "|           2011-03-02|      Inactive|    Tow Truck Driver|           NY|      10452|\n",
      "|           2019-05-14|        Active|       Ticket Seller|           NY|      10304|\n",
      "|           2012-02-13|      Inactive|      General Vendor|           NY|      11422|\n",
      "|           2017-03-23|        Active|       Ticket Seller|           NY|      11435|\n",
      "|           2014-04-15|      Inactive|    Tow Truck Driver|           NY|      10314|\n",
      "|           2018-12-19|      Inactive|Home Improvement ...|           NY|      10010|\n",
      "|           2018-07-05|        Active|           Locksmith|           NY|      10128|\n",
      "|           1997-04-08|      Inactive|              Garage|           NY|      11372|\n",
      "|           2001-04-02|      Inactive|Tobacco Retail De...|           NY|      11226|\n",
      "|           2008-07-09|      Inactive|    Tow Truck Driver|           NY|      11207|\n",
      "|           2014-03-10|      Inactive|      Pedicab Driver|           NY|      10019|\n",
      "|           2017-11-25|      Inactive|           Laundries|           NY|      11209|\n",
      "+---------------------+--------------+--------------------+-------------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#remove non NYC entries\n",
    "business_license_df = business_license_df.filter(business_license_df[\"Address_ZIP\"].isin(zips_lst))\n",
    "business_license_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will also label the borough for each license"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import when\n",
    "\n",
    "business_license_df = business_license_df.withColumn(\"Borough\", when(business_license_df.Address_ZIP.isin(manhattan_zips), \"Manhattan\")\n",
    "                                                     .when(business_license_df.Address_ZIP.isin(brooklyn_zips), \"Brooklyn\")\n",
    "                                                     .when(business_license_df.Address_ZIP.isin(queen_zips), \"Queens\")\n",
    "                                                     .when(business_license_df.Address_ZIP.isin(bronx_zips), \"Bronx\")\n",
    "                                                     .when(business_license_df.Address_ZIP.isin(statenisland_zips), \"Staten Island\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we want to look at the number of licenses created each year. We use a pyspark SQL query to do this. After, we then convert the SQL table to a new pyspark dataframe, which we futher convert back into a new pandas dataframe, so that we can export the table into a csv file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "vscode": {
     "languageId": "scala"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Opened Licenses</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>2011</td>\n",
       "      <td>11907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>2012</td>\n",
       "      <td>12351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>2013</td>\n",
       "      <td>11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>2014</td>\n",
       "      <td>10152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>2015</td>\n",
       "      <td>10525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>2016</td>\n",
       "      <td>10247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>2017</td>\n",
       "      <td>12693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>2018</td>\n",
       "      <td>12352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>2019</td>\n",
       "      <td>8032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>2020</td>\n",
       "      <td>3213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>2021</td>\n",
       "      <td>4141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>2022</td>\n",
       "      <td>4484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>2023</td>\n",
       "      <td>1338</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Year  Opened Licenses\n",
       "31  2011            11907\n",
       "32  2012            12351\n",
       "33  2013            11890\n",
       "34  2014            10152\n",
       "35  2015            10525\n",
       "36  2016            10247\n",
       "37  2017            12693\n",
       "38  2018            12352\n",
       "39  2019             8032\n",
       "40  2020             3213\n",
       "41  2021             4141\n",
       "42  2022             4484\n",
       "43  2023             1338"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.sql.functions import year\n",
    "\n",
    "#Use SQL to group the data by years and count number of licenses made\n",
    "\n",
    "business_license_df.createOrReplaceTempView(\"license\")\n",
    "business_license_by_year_df = spark.sql(\"SELECT YEAR(License_Creation_Date) AS Year, COUNT(*) AS Opened_Licenses FROM license GROUP BY YEAR(License_Creation_Date) ORDER BY year\")\n",
    "\n",
    "#turn dataframe into pandas df to export as csv\n",
    "business_license_by_year = business_license_by_year_df.toPandas()\n",
    "#rename column back into words separated by spaces\n",
    "business_license_by_year.rename(columns={'Opened_Licenses': 'Opened Licenses'}, inplace=True)\n",
    "display(business_license_by_year[business_license_by_year['Year'] > 2010])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "vscode": {
     "languageId": "scala"
    }
   },
   "outputs": [],
   "source": [
    "#export CSV file\n",
    "business_license_by_year.to_csv('cleaned_data/business_license_by_year_updated.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are doing the same thing here, except now we are grouping by Borough "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "vscode": {
     "languageId": "scala"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Borough</th>\n",
       "      <th>Opened Licenses</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>2019</td>\n",
       "      <td>Staten Island</td>\n",
       "      <td>464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>2019</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>2312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>2019</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>1570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>2019</td>\n",
       "      <td>Queens</td>\n",
       "      <td>2373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>2019</td>\n",
       "      <td>Bronx</td>\n",
       "      <td>1313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>2020</td>\n",
       "      <td>Staten Island</td>\n",
       "      <td>217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>2020</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>2020</td>\n",
       "      <td>Bronx</td>\n",
       "      <td>453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>2020</td>\n",
       "      <td>Queens</td>\n",
       "      <td>948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>2020</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>2021</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>2021</td>\n",
       "      <td>Staten Island</td>\n",
       "      <td>247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>2021</td>\n",
       "      <td>Queens</td>\n",
       "      <td>1286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>2021</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>1250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>2021</td>\n",
       "      <td>Bronx</td>\n",
       "      <td>663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>2022</td>\n",
       "      <td>Staten Island</td>\n",
       "      <td>263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>2022</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>1462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>2022</td>\n",
       "      <td>Queens</td>\n",
       "      <td>1224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>2022</td>\n",
       "      <td>Bronx</td>\n",
       "      <td>715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>2022</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>2023</td>\n",
       "      <td>Staten Island</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>2023</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>2023</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>2023</td>\n",
       "      <td>Bronx</td>\n",
       "      <td>246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>2023</td>\n",
       "      <td>Queens</td>\n",
       "      <td>366</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Year        Borough  Opened Licenses\n",
       "173  2019  Staten Island              464\n",
       "174  2019       Brooklyn             2312\n",
       "175  2019      Manhattan             1570\n",
       "176  2019         Queens             2373\n",
       "177  2019          Bronx             1313\n",
       "178  2020  Staten Island              217\n",
       "179  2020       Brooklyn              986\n",
       "180  2020          Bronx              453\n",
       "181  2020         Queens              948\n",
       "182  2020      Manhattan              609\n",
       "183  2021      Manhattan              695\n",
       "184  2021  Staten Island              247\n",
       "185  2021         Queens             1286\n",
       "186  2021       Brooklyn             1250\n",
       "187  2021          Bronx              663\n",
       "188  2022  Staten Island              263\n",
       "189  2022       Brooklyn             1462\n",
       "190  2022         Queens             1224\n",
       "191  2022          Bronx              715\n",
       "192  2022      Manhattan              820\n",
       "193  2023  Staten Island               77\n",
       "194  2023      Manhattan              216\n",
       "195  2023       Brooklyn              433\n",
       "196  2023          Bronx              246\n",
       "197  2023         Queens              366"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Use SQL to group the data by years and count number of licenses made\n",
    "business_license_by_borough_df = spark.sql(\"SELECT YEAR(License_Creation_Date) AS Year, Borough, COUNT(*) AS Opened_Licenses FROM license GROUP BY YEAR(License_Creation_Date), Borough ORDER BY year\")\n",
    "#convert to pandas\n",
    "business_license_by_borough = business_license_by_borough_df.toPandas()\n",
    "#rename column\n",
    "business_license_by_borough.rename(columns={'Opened_Licenses': 'Opened Licenses'}, inplace=True)\n",
    "display(business_license_by_borough[business_license_by_borough['Year'] > 2018])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "vscode": {
     "languageId": "scala"
    }
   },
   "outputs": [],
   "source": [
    "#export CSV\n",
    "business_license_by_borough.to_csv('cleaned_data/business_license_by_borough_updated.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once Again we repeat the same as above, except now we are grouping by industry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "vscode": {
     "languageId": "scala"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Industry</th>\n",
       "      <th>Opened Licenses</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023</td>\n",
       "      <td>General Vendor</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023</td>\n",
       "      <td>Car Wash</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023</td>\n",
       "      <td>Locksmith</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023</td>\n",
       "      <td>Ticket Seller</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023</td>\n",
       "      <td>Garage</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>2020</td>\n",
       "      <td>Booting Company</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>2020</td>\n",
       "      <td>Tow Truck Exemption</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>2020</td>\n",
       "      <td>Games of Chance</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>2020</td>\n",
       "      <td>Debt Collection Agency</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>2020</td>\n",
       "      <td>Locksmith Apprentice</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>170 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Year                Industry  Opened Licenses\n",
       "0    2023          General Vendor               20\n",
       "1    2023                Car Wash                8\n",
       "2    2023               Locksmith               37\n",
       "3    2023           Ticket Seller               44\n",
       "4    2023                  Garage               37\n",
       "..    ...                     ...              ...\n",
       "165  2020         Booting Company                1\n",
       "166  2020     Tow Truck Exemption                1\n",
       "167  2020         Games of Chance                3\n",
       "168  2020  Debt Collection Agency               15\n",
       "169  2020    Locksmith Apprentice                2\n",
       "\n",
       "[170 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Use SQL to group by indsutry\n",
    "business_license_by_ind_df = spark.sql(\"SELECT YEAR(License_Creation_Date) AS Year, Industry, COUNT(*) AS Opened_Licenses FROM license GROUP BY YEAR(License_Creation_Date), Industry ORDER BY year DESC\")\n",
    "#convert to pandas\n",
    "business_license_by_ind = business_license_by_ind_df.toPandas()\n",
    "#rename\n",
    "business_license_by_ind.rename(columns={'Opened_Licenses': 'Opened Licenses'}, inplace=True)\n",
    "display(business_license_by_ind[business_license_by_ind['Year'] > 2019])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "vscode": {
     "languageId": "scala"
    }
   },
   "outputs": [],
   "source": [
    "#export\n",
    "business_license_by_ind.to_csv('cleaned_data/business_license_by_industry_updated.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning: cases-by-day.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we start by reading the 'cases-by-day.csv' file into a pandas dataframe. We are doing this because we want to set the 'date_of_interest' column into a datetime datatype. This is so that later on when we convert it to a spark dataframe and try to perform SQL queries we can access that data by different dates. We then turn the pandas dataframe into a spark dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "vscode": {
     "languageId": "scala"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+----------+-------------------+-------------------+-----------------------+-------------+----------------------+----------------------+--------------------------+-------------+----------------------+----------------------+--------------------------+-------------+----------------------+----------------------+--------------------------+-------------+----------------------+----------------------+--------------------------+-------------+----------------------+----------------------+--------------------------+----------+\n",
      "|   date_of_interest|CASE_COUNT|PROBABLE_CASE_COUNT|CASE_COUNT_7DAY_AVG|ALL_CASE_COUNT_7DAY_AVG|BX_CASE_COUNT|BX_PROBABLE_CASE_COUNT|BX_CASE_COUNT_7DAY_AVG|BX_ALL_CASE_COUNT_7DAY_AVG|BK_CASE_COUNT|BK_PROBABLE_CASE_COUNT|BK_CASE_COUNT_7DAY_AVG|BK_ALL_CASE_COUNT_7DAY_AVG|MN_CASE_COUNT|MN_PROBABLE_CASE_COUNT|MN_CASE_COUNT_7DAY_AVG|MN_ALL_CASE_COUNT_7DAY_AVG|QN_CASE_COUNT|QN_PROBABLE_CASE_COUNT|QN_CASE_COUNT_7DAY_AVG|QN_ALL_CASE_COUNT_7DAY_AVG|SI_CASE_COUNT|SI_PROBABLE_CASE_COUNT|SI_CASE_COUNT_7DAY_AVG|SI_ALL_CASE_COUNT_7DAY_AVG|INCOMPLETE|\n",
      "+-------------------+----------+-------------------+-------------------+-----------------------+-------------+----------------------+----------------------+--------------------------+-------------+----------------------+----------------------+--------------------------+-------------+----------------------+----------------------+--------------------------+-------------+----------------------+----------------------+--------------------------+-------------+----------------------+----------------------+--------------------------+----------+\n",
      "|2020-02-29 00:00:00|         1|                  0|                  0|                      0|            0|                     0|                     0|                         0|            0|                     0|                     0|                         0|            1|                     0|                     0|                         0|            0|                     0|                     0|                         0|            0|                     0|                     0|                         0|         0|\n",
      "|2020-03-01 00:00:00|         0|                  0|                  0|                      0|            0|                     0|                     0|                         0|            0|                     0|                     0|                         0|            0|                     0|                     0|                         0|            0|                     0|                     0|                         0|            0|                     0|                     0|                         0|         0|\n",
      "|2020-03-02 00:00:00|         0|                  0|                  0|                      0|            0|                     0|                     0|                         0|            0|                     0|                     0|                         0|            0|                     0|                     0|                         0|            0|                     0|                     0|                         0|            0|                     0|                     0|                         0|         0|\n",
      "|2020-03-03 00:00:00|         1|                  0|                  0|                      0|            0|                     0|                     0|                         0|            0|                     0|                     0|                         0|            0|                     0|                     0|                         0|            1|                     0|                     0|                         0|            0|                     0|                     0|                         0|         0|\n",
      "|2020-03-04 00:00:00|         5|                  0|                  0|                      0|            0|                     0|                     0|                         0|            1|                     0|                     0|                         0|            2|                     0|                     0|                         0|            2|                     0|                     0|                         0|            0|                     0|                     0|                         0|         0|\n",
      "|2020-03-05 00:00:00|         3|                  0|                  0|                      0|            0|                     0|                     0|                         0|            3|                     0|                     0|                         0|            0|                     0|                     0|                         0|            0|                     0|                     0|                         0|            0|                     0|                     0|                         0|         0|\n",
      "|2020-03-06 00:00:00|         8|                  0|                  3|                      3|            2|                     0|                     0|                         0|            1|                     0|                     1|                         1|            3|                     0|                     1|                         1|            1|                     0|                     1|                         1|            1|                     0|                     0|                         0|         0|\n",
      "|2020-03-07 00:00:00|         7|                  0|                  3|                      3|            0|                     0|                     0|                         0|            2|                     0|                     1|                         1|            1|                     0|                     1|                         1|            3|                     0|                     1|                         1|            1|                     0|                     0|                         0|         0|\n",
      "|2020-03-08 00:00:00|        21|                  0|                  6|                      6|            3|                     0|                     1|                         1|            5|                     0|                     2|                         2|            6|                     0|                     2|                         2|            6|                     0|                     2|                         2|            1|                     0|                     0|                         0|         0|\n",
      "|2020-03-09 00:00:00|        57|                  0|                 15|                     15|            4|                     0|                     1|                         1|           16|                     0|                     4|                         4|           24|                     0|                     5|                         5|           10|                     0|                     3|                         3|            3|                     0|                     1|                         1|         0|\n",
      "|2020-03-10 00:00:00|        69|                  0|                 24|                     24|            8|                     0|                     2|                         2|           11|                     0|                     6|                         6|           24|                     0|                     9|                         9|           24|                     0|                     7|                         7|            2|                     0|                     1|                         1|         0|\n",
      "|2020-03-11 00:00:00|       155|                  0|                 46|                     46|           19|                     0|                     5|                         5|           31|                     0|                    10|                        10|           62|                     0|                    17|                        17|           40|                     0|                    12|                        12|            3|                     0|                     2|                         2|         0|\n",
      "|2020-03-12 00:00:00|       355|                  0|                 96|                     96|           29|                     0|                     9|                         9|           96|                     0|                    23|                        23|          137|                     0|                    37|                        37|           80|                     0|                    23|                        23|           13|                     0|                     3|                         3|         0|\n",
      "|2020-03-13 00:00:00|       619|                  0|                183|                    183|           79|                     0|                    20|                        20|          166|                     0|                    47|                        47|          182|                     0|                    62|                        62|          166|                     0|                    47|                        47|           26|                     0|                     7|                         7|         0|\n",
      "|2020-03-14 00:00:00|       642|                  1|                274|                    274|           86|                     0|                    33|                        33|          163|                     0|                    70|                        70|          176|                     1|                    87|                        87|          194|                     0|                    74|                        74|           23|                     0|                    10|                        10|         0|\n",
      "|2020-03-15 00:00:00|      1034|                  0|                419|                    419|          119|                     0|                    49|                        49|          432|                     0|                   131|                       131|          205|                     0|                   116|                       116|          231|                     0|                   106|                       106|           47|                     0|                    17|                        17|         0|\n",
      "|2020-03-16 00:00:00|      2121|                  2|                714|                    714|          305|                     0|                    92|                        92|          740|                     1|                   234|                       234|          457|                     0|                   178|                       178|          528|                     1|                   180|                       181|           91|                     0|                    29|                        29|         0|\n",
      "|2020-03-17 00:00:00|      2451|                  4|               1054|                   1055|          343|                     0|                   140|                       140|          783|                     3|                   344|                       345|          567|                     0|                   255|                       255|          650|                     0|                   270|                       270|          108|                     1|                    44|                        45|         0|\n",
      "|2020-03-18 00:00:00|      2971|                  5|               1456|                   1458|          482|                     1|                   206|                       206|          965|                     3|                   478|                       479|          538|                     1|                   323|                       323|          835|                     0|                   383|                       384|          150|                     0|                    65|                        66|         0|\n",
      "|2020-03-19 00:00:00|      3706|                  4|               1935|                   1937|          623|                     3|                   291|                       292|         1204|                     0|                   636|                       637|          555|                     1|                   383|                       383|         1065|                     0|                   524|                       524|          258|                     0|                   100|                       101|         0|\n",
      "+-------------------+----------+-------------------+-------------------+-----------------------+-------------+----------------------+----------------------+--------------------------+-------------+----------------------+----------------------+--------------------------+-------------+----------------------+----------------------+--------------------------+-------------+----------------------+----------------------+--------------------------+-------------+----------------------+----------------------+--------------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#read csv as pandas\n",
    "covid_numbers = pd.read_csv(\"data/cases-by-day.csv\")\n",
    "#turn column into datetime datatype\n",
    "covid_numbers['date_of_interest'] = pd.to_datetime(covid_numbers['date_of_interest'])\n",
    "\n",
    "#convert to a spark dataframe and create a tempview for sql queries\n",
    "covid_df = spark.createDataFrame(covid_numbers)\n",
    "covid_df.createOrReplaceTempView(\"covid\")\n",
    "covid_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The covid dataset is taken per day. However, what we are trying to do is get an average number of cases per month. To do this we perform a SQL query where we group the data by year and then group by month. For each group we will take the average number of cases for that month. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "vscode": {
     "languageId": "scala"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+------------------+-----------+\n",
      "|year|month|       avg_per_day|total_cases|\n",
      "+----+-----+------------------+-----------+\n",
      "|2020|    2|               1.0|          1|\n",
      "|2020|    3|2102.6451612903224|      65182|\n",
      "|2020|    4|            3643.2|     109296|\n",
      "|2020|    5| 916.6451612903226|      28416|\n",
      "|2020|    6|361.46666666666664|      10844|\n",
      "|2020|    7|315.93548387096774|       9794|\n",
      "|2020|    8|240.19354838709677|       7446|\n",
      "|2020|    9|             369.9|      11097|\n",
      "|2020|   10| 545.9677419354839|      16925|\n",
      "|2020|   11|1492.1666666666667|      44765|\n",
      "|2020|   12|3154.7419354838707|      97797|\n",
      "|2021|    1| 4471.774193548387|     138625|\n",
      "|2021|    2|3089.5714285714284|      86508|\n",
      "|2021|    3| 2969.516129032258|      92055|\n",
      "|2021|    4|1811.1666666666667|      54335|\n",
      "|2021|    5| 437.4193548387097|      13560|\n",
      "|2021|    6|175.43333333333334|       5263|\n",
      "|2021|    7| 607.1612903225806|      18822|\n",
      "|2021|    8|            1498.0|      46438|\n",
      "|2021|    9|            1302.9|      39087|\n",
      "+----+-----+------------------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import year, month, max,concat, col\n",
    "covid_df_total = spark.sql(\"SELECT YEAR(date_of_interest) AS year, MONTH(date_of_interest) AS month, AVG(CASE_COUNT) as avg_per_day, SUM(CASE_COUNT) as total_cases FROM covid GROUP BY YEAR(date_of_interest), MONTH(date_of_interest) ORDER BY year, month\")\n",
    "covid_df_total.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another issue we are facing is that the year and month are now in separte columns. The next thing we do is combine the two columns. We start by converting the pyspark dataframe into a pandas dataframe. Next we append the year and month together and separting them by a period and store this as a new column in the dataframe. 2020 1 becomes 2020.1. Finally, we select only the cases column and the newly created year_month column. The purpose of combining the month and year columns is so that when we want to plot the data we can have both the year and month included in the plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "vscode": {
     "languageId": "scala"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>avg_per_day</th>\n",
       "      <th>total_cases</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>2020-02-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2102.645161</td>\n",
       "      <td>65182</td>\n",
       "      <td>2020-03-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3643.200000</td>\n",
       "      <td>109296</td>\n",
       "      <td>2020-04-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>916.645161</td>\n",
       "      <td>28416</td>\n",
       "      <td>2020-05-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>361.466667</td>\n",
       "      <td>10844</td>\n",
       "      <td>2020-06-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>315.935484</td>\n",
       "      <td>9794</td>\n",
       "      <td>2020-07-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>240.193548</td>\n",
       "      <td>7446</td>\n",
       "      <td>2020-08-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>369.900000</td>\n",
       "      <td>11097</td>\n",
       "      <td>2020-09-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>545.967742</td>\n",
       "      <td>16925</td>\n",
       "      <td>2020-10-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1492.166667</td>\n",
       "      <td>44765</td>\n",
       "      <td>2020-11-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3154.741935</td>\n",
       "      <td>97797</td>\n",
       "      <td>2020-12-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>4471.774194</td>\n",
       "      <td>138625</td>\n",
       "      <td>2021-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>3089.571429</td>\n",
       "      <td>86508</td>\n",
       "      <td>2021-02-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2969.516129</td>\n",
       "      <td>92055</td>\n",
       "      <td>2021-03-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1811.166667</td>\n",
       "      <td>54335</td>\n",
       "      <td>2021-04-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>437.419355</td>\n",
       "      <td>13560</td>\n",
       "      <td>2021-05-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>175.433333</td>\n",
       "      <td>5263</td>\n",
       "      <td>2021-06-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>607.161290</td>\n",
       "      <td>18822</td>\n",
       "      <td>2021-07-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1498.000000</td>\n",
       "      <td>46438</td>\n",
       "      <td>2021-08-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1302.900000</td>\n",
       "      <td>39087</td>\n",
       "      <td>2021-09-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>815.451613</td>\n",
       "      <td>25279</td>\n",
       "      <td>2021-10-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1065.966667</td>\n",
       "      <td>31979</td>\n",
       "      <td>2021-11-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>16335.387097</td>\n",
       "      <td>506397</td>\n",
       "      <td>2021-12-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>14850.387097</td>\n",
       "      <td>460362</td>\n",
       "      <td>2022-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>978.821429</td>\n",
       "      <td>27407</td>\n",
       "      <td>2022-02-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>832.516129</td>\n",
       "      <td>25808</td>\n",
       "      <td>2022-03-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1965.200000</td>\n",
       "      <td>58956</td>\n",
       "      <td>2022-04-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>3288.806452</td>\n",
       "      <td>101953</td>\n",
       "      <td>2022-05-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2691.133333</td>\n",
       "      <td>80734</td>\n",
       "      <td>2022-06-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>3302.741935</td>\n",
       "      <td>102385</td>\n",
       "      <td>2022-07-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>2159.451613</td>\n",
       "      <td>66943</td>\n",
       "      <td>2022-08-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>1579.933333</td>\n",
       "      <td>47398</td>\n",
       "      <td>2022-09-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>1614.000000</td>\n",
       "      <td>50034</td>\n",
       "      <td>2022-10-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>2241.400000</td>\n",
       "      <td>67242</td>\n",
       "      <td>2022-11-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>2727.645161</td>\n",
       "      <td>84557</td>\n",
       "      <td>2022-12-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>1857.967742</td>\n",
       "      <td>57597</td>\n",
       "      <td>2023-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>782.071429</td>\n",
       "      <td>21898</td>\n",
       "      <td>2023-02-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>380.258065</td>\n",
       "      <td>11788</td>\n",
       "      <td>2023-03-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>209.375000</td>\n",
       "      <td>5025</td>\n",
       "      <td>2023-04-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     avg_per_day  total_cases       date\n",
       "0       1.000000            1 2020-02-01\n",
       "1    2102.645161        65182 2020-03-01\n",
       "2    3643.200000       109296 2020-04-01\n",
       "3     916.645161        28416 2020-05-01\n",
       "4     361.466667        10844 2020-06-01\n",
       "5     315.935484         9794 2020-07-01\n",
       "6     240.193548         7446 2020-08-01\n",
       "7     369.900000        11097 2020-09-01\n",
       "8     545.967742        16925 2020-10-01\n",
       "9    1492.166667        44765 2020-11-01\n",
       "10   3154.741935        97797 2020-12-01\n",
       "11   4471.774194       138625 2021-01-01\n",
       "12   3089.571429        86508 2021-02-01\n",
       "13   2969.516129        92055 2021-03-01\n",
       "14   1811.166667        54335 2021-04-01\n",
       "15    437.419355        13560 2021-05-01\n",
       "16    175.433333         5263 2021-06-01\n",
       "17    607.161290        18822 2021-07-01\n",
       "18   1498.000000        46438 2021-08-01\n",
       "19   1302.900000        39087 2021-09-01\n",
       "20    815.451613        25279 2021-10-01\n",
       "21   1065.966667        31979 2021-11-01\n",
       "22  16335.387097       506397 2021-12-01\n",
       "23  14850.387097       460362 2022-01-01\n",
       "24    978.821429        27407 2022-02-01\n",
       "25    832.516129        25808 2022-03-01\n",
       "26   1965.200000        58956 2022-04-01\n",
       "27   3288.806452       101953 2022-05-01\n",
       "28   2691.133333        80734 2022-06-01\n",
       "29   3302.741935       102385 2022-07-01\n",
       "30   2159.451613        66943 2022-08-01\n",
       "31   1579.933333        47398 2022-09-01\n",
       "32   1614.000000        50034 2022-10-01\n",
       "33   2241.400000        67242 2022-11-01\n",
       "34   2727.645161        84557 2022-12-01\n",
       "35   1857.967742        57597 2023-01-01\n",
       "36    782.071429        21898 2023-02-01\n",
       "37    380.258065        11788 2023-03-01\n",
       "38    209.375000         5025 2023-04-01"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#convert to pandas\n",
    "covid_numbers = covid_df_total.toPandas()\n",
    "#combine year and month columns as a new column 'year_month'\n",
    "covid_numbers['date'] = pd.to_datetime(covid_numbers['year'].astype(str) + '-' + covid_numbers['month'].astype(str))\n",
    "#take only the cases column and 'year_month' column\n",
    "covid_numbers = covid_numbers.iloc[:,2:5]\n",
    "covid_numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "vscode": {
     "languageId": "scala"
    }
   },
   "outputs": [],
   "source": [
    "#export as csv\n",
    "covid_numbers.to_csv('cleaned_data/covid_numbers_updated.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning: savings.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I want to compare the data of covid cases to amount of personal savings. From the previous step, the 'covid_numbers_updated.csv' reads the months as '2020.1', '2020.2', etc. The Personal savings.csv does not group the data by this. In the  savings data, the columns are grouped by year in one row and by month in another row. In order to compare the two data sets I want to format the dates of the Personal savings data to match the updated covid numbers data. I start by reading the data into a pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "vscode": {
     "languageId": "scala"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Line</th>\n",
       "      <th>Unnamed: 1</th>\n",
       "      <th>2017</th>\n",
       "      <th>2017.1</th>\n",
       "      <th>2017.2</th>\n",
       "      <th>2017.3</th>\n",
       "      <th>2017.4</th>\n",
       "      <th>2017.5</th>\n",
       "      <th>2017.6</th>\n",
       "      <th>2017.7</th>\n",
       "      <th>...</th>\n",
       "      <th>2022.5</th>\n",
       "      <th>2022.6</th>\n",
       "      <th>2022.7</th>\n",
       "      <th>2022.8</th>\n",
       "      <th>2022.9</th>\n",
       "      <th>2022.10</th>\n",
       "      <th>2022.11</th>\n",
       "      <th>2023</th>\n",
       "      <th>2023.1</th>\n",
       "      <th>2023.2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Line</td>\n",
       "      <td>NaN</td>\n",
       "      <td>JAN</td>\n",
       "      <td>FEB</td>\n",
       "      <td>MAR</td>\n",
       "      <td>APR</td>\n",
       "      <td>MAY</td>\n",
       "      <td>JUN</td>\n",
       "      <td>JUL</td>\n",
       "      <td>AUG</td>\n",
       "      <td>...</td>\n",
       "      <td>JUN</td>\n",
       "      <td>JUL</td>\n",
       "      <td>AUG</td>\n",
       "      <td>SEP</td>\n",
       "      <td>OCT</td>\n",
       "      <td>NOV</td>\n",
       "      <td>DEC</td>\n",
       "      <td>JAN</td>\n",
       "      <td>FEB</td>\n",
       "      <td>MAR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Personal income</td>\n",
       "      <td>16489261</td>\n",
       "      <td>16557491</td>\n",
       "      <td>16609059</td>\n",
       "      <td>16667168</td>\n",
       "      <td>16763660</td>\n",
       "      <td>16791030</td>\n",
       "      <td>16847997</td>\n",
       "      <td>16907887</td>\n",
       "      <td>...</td>\n",
       "      <td>21687046</td>\n",
       "      <td>21852289</td>\n",
       "      <td>21975795</td>\n",
       "      <td>22080374</td>\n",
       "      <td>22283009</td>\n",
       "      <td>22375915</td>\n",
       "      <td>22446071</td>\n",
       "      <td>22575592</td>\n",
       "      <td>22649070</td>\n",
       "      <td>22716956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Compensation of employees</td>\n",
       "      <td>10194656</td>\n",
       "      <td>10231767</td>\n",
       "      <td>10246421</td>\n",
       "      <td>10298027</td>\n",
       "      <td>10329427</td>\n",
       "      <td>10380266</td>\n",
       "      <td>10432173</td>\n",
       "      <td>10467818</td>\n",
       "      <td>...</td>\n",
       "      <td>13468831</td>\n",
       "      <td>13654085</td>\n",
       "      <td>13754853</td>\n",
       "      <td>13856069</td>\n",
       "      <td>13921039</td>\n",
       "      <td>13977288</td>\n",
       "      <td>14019434</td>\n",
       "      <td>14138891</td>\n",
       "      <td>14178693</td>\n",
       "      <td>14224868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Wages and salaries</td>\n",
       "      <td>8286937</td>\n",
       "      <td>8318008</td>\n",
       "      <td>8328008</td>\n",
       "      <td>8371638</td>\n",
       "      <td>8396316</td>\n",
       "      <td>8438386</td>\n",
       "      <td>8481031</td>\n",
       "      <td>8508186</td>\n",
       "      <td>...</td>\n",
       "      <td>11103991</td>\n",
       "      <td>11271794</td>\n",
       "      <td>11360707</td>\n",
       "      <td>11450576</td>\n",
       "      <td>11506774</td>\n",
       "      <td>11553505</td>\n",
       "      <td>11587745</td>\n",
       "      <td>11693839</td>\n",
       "      <td>11726779</td>\n",
       "      <td>11765591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Private industries</td>\n",
       "      <td>6958868</td>\n",
       "      <td>6986215</td>\n",
       "      <td>6993336</td>\n",
       "      <td>7035182</td>\n",
       "      <td>7056407</td>\n",
       "      <td>7093815</td>\n",
       "      <td>7130552</td>\n",
       "      <td>7156181</td>\n",
       "      <td>...</td>\n",
       "      <td>9500072</td>\n",
       "      <td>9656398</td>\n",
       "      <td>9735876</td>\n",
       "      <td>9819494</td>\n",
       "      <td>9872200</td>\n",
       "      <td>9908691</td>\n",
       "      <td>9937328</td>\n",
       "      <td>10033610</td>\n",
       "      <td>10059718</td>\n",
       "      <td>10091831</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 77 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Line                      Unnamed: 1      2017    2017.1    2017.2  \\\n",
       "0  Line                             NaN       JAN       FEB       MAR   \n",
       "1     1                 Personal income  16489261  16557491  16609059   \n",
       "2     2       Compensation of employees  10194656  10231767  10246421   \n",
       "3     3              Wages and salaries   8286937   8318008   8328008   \n",
       "4     4              Private industries   6958868   6986215   6993336   \n",
       "\n",
       "     2017.3    2017.4    2017.5    2017.6    2017.7  ...    2022.5    2022.6  \\\n",
       "0       APR       MAY       JUN       JUL       AUG  ...       JUN       JUL   \n",
       "1  16667168  16763660  16791030  16847997  16907887  ...  21687046  21852289   \n",
       "2  10298027  10329427  10380266  10432173  10467818  ...  13468831  13654085   \n",
       "3   8371638   8396316   8438386   8481031   8508186  ...  11103991  11271794   \n",
       "4   7035182   7056407   7093815   7130552   7156181  ...   9500072   9656398   \n",
       "\n",
       "     2022.7    2022.8    2022.9   2022.10   2022.11      2023    2023.1  \\\n",
       "0       AUG       SEP       OCT       NOV       DEC       JAN       FEB   \n",
       "1  21975795  22080374  22283009  22375915  22446071  22575592  22649070   \n",
       "2  13754853  13856069  13921039  13977288  14019434  14138891  14178693   \n",
       "3  11360707  11450576  11506774  11553505  11587745  11693839  11726779   \n",
       "4   9735876   9819494   9872200   9908691   9937328  10033610  10059718   \n",
       "\n",
       "     2023.2  \n",
       "0       MAR  \n",
       "1  22716956  \n",
       "2  14224868  \n",
       "3  11765591  \n",
       "4  10091831  \n",
       "\n",
       "[5 rows x 77 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import decimal\n",
    "income_disposition = pd.read_csv(\"data/savings.csv\")\n",
    "income_disposition.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the first row of the table lists the months:\"JAN\",\"FEB\",etc. We also notice that the labels of the years already indicate the month with a number. Therefore, we do not really need the row with the months so we can delete that. We also don't need the first column of the dataset with the line count. We also notice that there is a row in the data that has empty values. We can either delete it or fill it in with 0's, in this case we fill it in with 0's. Also we want to make sure the data is the correct datatype, so we change every column to a float datatype. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "vscode": {
     "languageId": "scala"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 1</th>\n",
       "      <th>2017</th>\n",
       "      <th>2017.1</th>\n",
       "      <th>2017.2</th>\n",
       "      <th>2017.3</th>\n",
       "      <th>2017.4</th>\n",
       "      <th>2017.5</th>\n",
       "      <th>2017.6</th>\n",
       "      <th>2017.7</th>\n",
       "      <th>2017.8</th>\n",
       "      <th>...</th>\n",
       "      <th>2022.5</th>\n",
       "      <th>2022.6</th>\n",
       "      <th>2022.7</th>\n",
       "      <th>2022.8</th>\n",
       "      <th>2022.9</th>\n",
       "      <th>2022.10</th>\n",
       "      <th>2022.11</th>\n",
       "      <th>2023</th>\n",
       "      <th>2023.1</th>\n",
       "      <th>2023.2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Personal income</td>\n",
       "      <td>16489261.0</td>\n",
       "      <td>16557491.0</td>\n",
       "      <td>16609059.0</td>\n",
       "      <td>16667168.0</td>\n",
       "      <td>16763660.0</td>\n",
       "      <td>16791030.0</td>\n",
       "      <td>16847997.0</td>\n",
       "      <td>16907887.0</td>\n",
       "      <td>17008347.0</td>\n",
       "      <td>...</td>\n",
       "      <td>21687046.0</td>\n",
       "      <td>21852289.0</td>\n",
       "      <td>21975795.0</td>\n",
       "      <td>22080374.0</td>\n",
       "      <td>22283009.0</td>\n",
       "      <td>22375915.0</td>\n",
       "      <td>22446071.0</td>\n",
       "      <td>22575592.0</td>\n",
       "      <td>22649070.0</td>\n",
       "      <td>22716956.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Compensation of employees</td>\n",
       "      <td>10194656.0</td>\n",
       "      <td>10231767.0</td>\n",
       "      <td>10246421.0</td>\n",
       "      <td>10298027.0</td>\n",
       "      <td>10329427.0</td>\n",
       "      <td>10380266.0</td>\n",
       "      <td>10432173.0</td>\n",
       "      <td>10467818.0</td>\n",
       "      <td>10535107.0</td>\n",
       "      <td>...</td>\n",
       "      <td>13468831.0</td>\n",
       "      <td>13654085.0</td>\n",
       "      <td>13754853.0</td>\n",
       "      <td>13856069.0</td>\n",
       "      <td>13921039.0</td>\n",
       "      <td>13977288.0</td>\n",
       "      <td>14019434.0</td>\n",
       "      <td>14138891.0</td>\n",
       "      <td>14178693.0</td>\n",
       "      <td>14224868.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Wages and salaries</td>\n",
       "      <td>8286937.0</td>\n",
       "      <td>8318008.0</td>\n",
       "      <td>8328008.0</td>\n",
       "      <td>8371638.0</td>\n",
       "      <td>8396316.0</td>\n",
       "      <td>8438386.0</td>\n",
       "      <td>8481031.0</td>\n",
       "      <td>8508186.0</td>\n",
       "      <td>8565557.0</td>\n",
       "      <td>...</td>\n",
       "      <td>11103991.0</td>\n",
       "      <td>11271794.0</td>\n",
       "      <td>11360707.0</td>\n",
       "      <td>11450576.0</td>\n",
       "      <td>11506774.0</td>\n",
       "      <td>11553505.0</td>\n",
       "      <td>11587745.0</td>\n",
       "      <td>11693839.0</td>\n",
       "      <td>11726779.0</td>\n",
       "      <td>11765591.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Private industries</td>\n",
       "      <td>6958868.0</td>\n",
       "      <td>6986215.0</td>\n",
       "      <td>6993336.0</td>\n",
       "      <td>7035182.0</td>\n",
       "      <td>7056407.0</td>\n",
       "      <td>7093815.0</td>\n",
       "      <td>7130552.0</td>\n",
       "      <td>7156181.0</td>\n",
       "      <td>7208255.0</td>\n",
       "      <td>...</td>\n",
       "      <td>9500072.0</td>\n",
       "      <td>9656398.0</td>\n",
       "      <td>9735876.0</td>\n",
       "      <td>9819494.0</td>\n",
       "      <td>9872200.0</td>\n",
       "      <td>9908691.0</td>\n",
       "      <td>9937328.0</td>\n",
       "      <td>10033610.0</td>\n",
       "      <td>10059718.0</td>\n",
       "      <td>10091831.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Government</td>\n",
       "      <td>1328069.0</td>\n",
       "      <td>1331793.0</td>\n",
       "      <td>1334672.0</td>\n",
       "      <td>1336457.0</td>\n",
       "      <td>1339910.0</td>\n",
       "      <td>1344571.0</td>\n",
       "      <td>1350479.0</td>\n",
       "      <td>1352005.0</td>\n",
       "      <td>1357303.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1603920.0</td>\n",
       "      <td>1615396.0</td>\n",
       "      <td>1624831.0</td>\n",
       "      <td>1631082.0</td>\n",
       "      <td>1634574.0</td>\n",
       "      <td>1644813.0</td>\n",
       "      <td>1650417.0</td>\n",
       "      <td>1660229.0</td>\n",
       "      <td>1667061.0</td>\n",
       "      <td>1673760.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 76 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Unnamed: 1        2017      2017.1      2017.2  \\\n",
       "1                 Personal income  16489261.0  16557491.0  16609059.0   \n",
       "2       Compensation of employees  10194656.0  10231767.0  10246421.0   \n",
       "3              Wages and salaries   8286937.0   8318008.0   8328008.0   \n",
       "4              Private industries   6958868.0   6986215.0   6993336.0   \n",
       "5                      Government   1328069.0   1331793.0   1334672.0   \n",
       "\n",
       "       2017.3      2017.4      2017.5      2017.6      2017.7      2017.8  \\\n",
       "1  16667168.0  16763660.0  16791030.0  16847997.0  16907887.0  17008347.0   \n",
       "2  10298027.0  10329427.0  10380266.0  10432173.0  10467818.0  10535107.0   \n",
       "3   8371638.0   8396316.0   8438386.0   8481031.0   8508186.0   8565557.0   \n",
       "4   7035182.0   7056407.0   7093815.0   7130552.0   7156181.0   7208255.0   \n",
       "5   1336457.0   1339910.0   1344571.0   1350479.0   1352005.0   1357303.0   \n",
       "\n",
       "   ...      2022.5      2022.6      2022.7      2022.8      2022.9  \\\n",
       "1  ...  21687046.0  21852289.0  21975795.0  22080374.0  22283009.0   \n",
       "2  ...  13468831.0  13654085.0  13754853.0  13856069.0  13921039.0   \n",
       "3  ...  11103991.0  11271794.0  11360707.0  11450576.0  11506774.0   \n",
       "4  ...   9500072.0   9656398.0   9735876.0   9819494.0   9872200.0   \n",
       "5  ...   1603920.0   1615396.0   1624831.0   1631082.0   1634574.0   \n",
       "\n",
       "      2022.10     2022.11        2023      2023.1      2023.2  \n",
       "1  22375915.0  22446071.0  22575592.0  22649070.0  22716956.0  \n",
       "2  13977288.0  14019434.0  14138891.0  14178693.0  14224868.0  \n",
       "3  11553505.0  11587745.0  11693839.0  11726779.0  11765591.0  \n",
       "4   9908691.0   9937328.0  10033610.0  10059718.0  10091831.0  \n",
       "5   1644813.0   1650417.0   1660229.0   1667061.0   1673760.0  \n",
       "\n",
       "[5 rows x 76 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#drop row with months and drop first column with row count\n",
    "income_disposition = income_disposition.drop(['Line'], axis = 1)\n",
    "income_disposition= income_disposition.iloc[1:, :]\n",
    "\n",
    "#fill empty rows with 0\n",
    "income_disposition = income_disposition.fillna(0)\n",
    "\n",
    "#change column datatypes to floats\n",
    "cols = income_disposition.columns\n",
    "cols = cols[1:]\n",
    "for col in cols:\n",
    "    income_disposition[col] = income_disposition[col].astype(\"float\")\n",
    "\n",
    "income_disposition.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another thing we notice is that the years do not quite match up with year_month labels of our covid data. In our covid data, the year_month is represented as by date time format while this dataset has it as \"2017.1\". We will amend this by converting the dates back into a datetime format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['type', '2017-01-01', '2017-02-01', '2017-03-01', '2017-04-01', '2017-05-01', '2017-06-01', '2017-07-01', '2017-08-01', '2017-09-01', '2017-10-01', '2017-11-01', '2017-12-01', '2018-01-01', '2018-02-01', '2018-03-01', '2018-04-01', '2018-05-01', '2018-06-01', '2018-07-01', '2018-08-01', '2018-09-01', '2018-10-01', '2018-11-01', '2018-12-01', '2019-01-01', '2019-02-01', '2019-03-01', '2019-04-01', '2019-05-01', '2019-06-01', '2019-07-01', '2019-08-01', '2019-09-01', '2019-10-01', '2019-11-01', '2019-12-01', '2020-01-01', '2020-02-01', '2020-03-01', '2020-04-01', '2020-05-01', '2020-06-01', '2020-07-01', '2020-08-01', '2020-09-01', '2020-10-01', '2020-11-01', '2020-12-01', '2021-01-01', '2021-02-01', '2021-03-01', '2021-04-01', '2021-05-01', '2021-06-01', '2021-07-01', '2021-08-01', '2021-09-01', '2021-10-01', '2021-11-01', '2021-12-01', '2022-01-01', '2022-02-01', '2022-03-01', '2022-04-01', '2022-05-01', '2022-06-01', '2022-07-01', '2022-08-01', '2022-09-01', '2022-10-01', '2022-11-01', '2022-12-01', '2023-01-01', '2023-02-01', '2023-03-01']\n"
     ]
    }
   ],
   "source": [
    "new_cols = [\"type\"]\n",
    "\n",
    "for col in income_disposition.columns[1:]:\n",
    "    #split column name by .\n",
    "    col = col.split(\".\")\n",
    "    \n",
    "    #if this is just 2017\n",
    "    if len(col) == 1:\n",
    "        new_name = col[0] + \"-01\" + \"-01\" \n",
    "        \n",
    "    #otherwise add 1 to month\n",
    "    else:\n",
    "        month = str(int(col[-1]) + 1)\n",
    "        \n",
    "        #if our month is <10 we need to append 0 in front \n",
    "        if int(month) < 10:\n",
    "            month = \"0\" + month\n",
    "        \n",
    "        #format name\n",
    "        new_name = col[0] + \"-\" + month + \"-01\" \n",
    "    \n",
    "    new_cols.append(new_name)\n",
    "    \n",
    "print(new_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "vscode": {
     "languageId": "scala"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>2017-01-01</th>\n",
       "      <th>2017-02-01</th>\n",
       "      <th>2017-03-01</th>\n",
       "      <th>2017-04-01</th>\n",
       "      <th>2017-05-01</th>\n",
       "      <th>2017-06-01</th>\n",
       "      <th>2017-07-01</th>\n",
       "      <th>2017-08-01</th>\n",
       "      <th>2017-09-01</th>\n",
       "      <th>...</th>\n",
       "      <th>2022-06-01</th>\n",
       "      <th>2022-07-01</th>\n",
       "      <th>2022-08-01</th>\n",
       "      <th>2022-09-01</th>\n",
       "      <th>2022-10-01</th>\n",
       "      <th>2022-11-01</th>\n",
       "      <th>2022-12-01</th>\n",
       "      <th>2023-01-01</th>\n",
       "      <th>2023-02-01</th>\n",
       "      <th>2023-03-01</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Personal income</td>\n",
       "      <td>16489261.0</td>\n",
       "      <td>16557491.0</td>\n",
       "      <td>16609059.0</td>\n",
       "      <td>16667168.0</td>\n",
       "      <td>16763660.0</td>\n",
       "      <td>16791030.0</td>\n",
       "      <td>16847997.0</td>\n",
       "      <td>16907887.0</td>\n",
       "      <td>17008347.0</td>\n",
       "      <td>...</td>\n",
       "      <td>21687046.0</td>\n",
       "      <td>21852289.0</td>\n",
       "      <td>21975795.0</td>\n",
       "      <td>22080374.0</td>\n",
       "      <td>22283009.0</td>\n",
       "      <td>22375915.0</td>\n",
       "      <td>22446071.0</td>\n",
       "      <td>22575592.0</td>\n",
       "      <td>22649070.0</td>\n",
       "      <td>22716956.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Compensation of employees</td>\n",
       "      <td>10194656.0</td>\n",
       "      <td>10231767.0</td>\n",
       "      <td>10246421.0</td>\n",
       "      <td>10298027.0</td>\n",
       "      <td>10329427.0</td>\n",
       "      <td>10380266.0</td>\n",
       "      <td>10432173.0</td>\n",
       "      <td>10467818.0</td>\n",
       "      <td>10535107.0</td>\n",
       "      <td>...</td>\n",
       "      <td>13468831.0</td>\n",
       "      <td>13654085.0</td>\n",
       "      <td>13754853.0</td>\n",
       "      <td>13856069.0</td>\n",
       "      <td>13921039.0</td>\n",
       "      <td>13977288.0</td>\n",
       "      <td>14019434.0</td>\n",
       "      <td>14138891.0</td>\n",
       "      <td>14178693.0</td>\n",
       "      <td>14224868.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Wages and salaries</td>\n",
       "      <td>8286937.0</td>\n",
       "      <td>8318008.0</td>\n",
       "      <td>8328008.0</td>\n",
       "      <td>8371638.0</td>\n",
       "      <td>8396316.0</td>\n",
       "      <td>8438386.0</td>\n",
       "      <td>8481031.0</td>\n",
       "      <td>8508186.0</td>\n",
       "      <td>8565557.0</td>\n",
       "      <td>...</td>\n",
       "      <td>11103991.0</td>\n",
       "      <td>11271794.0</td>\n",
       "      <td>11360707.0</td>\n",
       "      <td>11450576.0</td>\n",
       "      <td>11506774.0</td>\n",
       "      <td>11553505.0</td>\n",
       "      <td>11587745.0</td>\n",
       "      <td>11693839.0</td>\n",
       "      <td>11726779.0</td>\n",
       "      <td>11765591.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Private industries</td>\n",
       "      <td>6958868.0</td>\n",
       "      <td>6986215.0</td>\n",
       "      <td>6993336.0</td>\n",
       "      <td>7035182.0</td>\n",
       "      <td>7056407.0</td>\n",
       "      <td>7093815.0</td>\n",
       "      <td>7130552.0</td>\n",
       "      <td>7156181.0</td>\n",
       "      <td>7208255.0</td>\n",
       "      <td>...</td>\n",
       "      <td>9500072.0</td>\n",
       "      <td>9656398.0</td>\n",
       "      <td>9735876.0</td>\n",
       "      <td>9819494.0</td>\n",
       "      <td>9872200.0</td>\n",
       "      <td>9908691.0</td>\n",
       "      <td>9937328.0</td>\n",
       "      <td>10033610.0</td>\n",
       "      <td>10059718.0</td>\n",
       "      <td>10091831.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Government</td>\n",
       "      <td>1328069.0</td>\n",
       "      <td>1331793.0</td>\n",
       "      <td>1334672.0</td>\n",
       "      <td>1336457.0</td>\n",
       "      <td>1339910.0</td>\n",
       "      <td>1344571.0</td>\n",
       "      <td>1350479.0</td>\n",
       "      <td>1352005.0</td>\n",
       "      <td>1357303.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1603920.0</td>\n",
       "      <td>1615396.0</td>\n",
       "      <td>1624831.0</td>\n",
       "      <td>1631082.0</td>\n",
       "      <td>1634574.0</td>\n",
       "      <td>1644813.0</td>\n",
       "      <td>1650417.0</td>\n",
       "      <td>1660229.0</td>\n",
       "      <td>1667061.0</td>\n",
       "      <td>1673760.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 76 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             type  2017-01-01  2017-02-01  2017-03-01  \\\n",
       "1                 Personal income  16489261.0  16557491.0  16609059.0   \n",
       "2       Compensation of employees  10194656.0  10231767.0  10246421.0   \n",
       "3              Wages and salaries   8286937.0   8318008.0   8328008.0   \n",
       "4              Private industries   6958868.0   6986215.0   6993336.0   \n",
       "5                      Government   1328069.0   1331793.0   1334672.0   \n",
       "\n",
       "   2017-04-01  2017-05-01  2017-06-01  2017-07-01  2017-08-01  2017-09-01  \\\n",
       "1  16667168.0  16763660.0  16791030.0  16847997.0  16907887.0  17008347.0   \n",
       "2  10298027.0  10329427.0  10380266.0  10432173.0  10467818.0  10535107.0   \n",
       "3   8371638.0   8396316.0   8438386.0   8481031.0   8508186.0   8565557.0   \n",
       "4   7035182.0   7056407.0   7093815.0   7130552.0   7156181.0   7208255.0   \n",
       "5   1336457.0   1339910.0   1344571.0   1350479.0   1352005.0   1357303.0   \n",
       "\n",
       "   ...  2022-06-01  2022-07-01  2022-08-01  2022-09-01  2022-10-01  \\\n",
       "1  ...  21687046.0  21852289.0  21975795.0  22080374.0  22283009.0   \n",
       "2  ...  13468831.0  13654085.0  13754853.0  13856069.0  13921039.0   \n",
       "3  ...  11103991.0  11271794.0  11360707.0  11450576.0  11506774.0   \n",
       "4  ...   9500072.0   9656398.0   9735876.0   9819494.0   9872200.0   \n",
       "5  ...   1603920.0   1615396.0   1624831.0   1631082.0   1634574.0   \n",
       "\n",
       "   2022-11-01  2022-12-01  2023-01-01  2023-02-01  2023-03-01  \n",
       "1  22375915.0  22446071.0  22575592.0  22649070.0  22716956.0  \n",
       "2  13977288.0  14019434.0  14138891.0  14178693.0  14224868.0  \n",
       "3  11553505.0  11587745.0  11693839.0  11726779.0  11765591.0  \n",
       "4   9908691.0   9937328.0  10033610.0  10059718.0  10091831.0  \n",
       "5   1644813.0   1650417.0   1660229.0   1667061.0   1673760.0  \n",
       "\n",
       "[5 rows x 76 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fix columns\n",
    "income_disposition.columns = new_cols\n",
    "income_disposition.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "vscode": {
     "languageId": "scala"
    }
   },
   "outputs": [],
   "source": [
    "#export as csv\n",
    "income_disposition.to_csv('cleaned_data/savings_updated.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning: us_small_bus.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a simple data set about the number of US small businesses over the years. It is a small dataset, that does not require much cleaning. However, there are small things that need to be fixed. We start by reading the dataset into a pandas dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "vscode": {
     "languageId": "scala"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Line</th>\n",
       "      <th>Unnamed: 1</th>\n",
       "      <th>2014</th>\n",
       "      <th>2015</th>\n",
       "      <th>2016</th>\n",
       "      <th>2017</th>\n",
       "      <th>2018</th>\n",
       "      <th>2019</th>\n",
       "      <th>2020</th>\n",
       "      <th>2021</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Self-employed persons1</td>\n",
       "      <td>9358.0</td>\n",
       "      <td>9508.0</td>\n",
       "      <td>9604.0</td>\n",
       "      <td>9525.0</td>\n",
       "      <td>9707.0</td>\n",
       "      <td>9539.0</td>\n",
       "      <td>9253.0</td>\n",
       "      <td>9956.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>Agriculture, forestry, fishing, and hunting</td>\n",
       "      <td>757.0</td>\n",
       "      <td>843.0</td>\n",
       "      <td>852.0</td>\n",
       "      <td>790.0</td>\n",
       "      <td>766.0</td>\n",
       "      <td>741.0</td>\n",
       "      <td>741.0</td>\n",
       "      <td>737.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>Farms2</td>\n",
       "      <td>680.0</td>\n",
       "      <td>760.0</td>\n",
       "      <td>771.0</td>\n",
       "      <td>711.0</td>\n",
       "      <td>684.0</td>\n",
       "      <td>664.0</td>\n",
       "      <td>669.0</td>\n",
       "      <td>669.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>Forestry, fishing and related activities</td>\n",
       "      <td>77.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>68.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Line                                    Unnamed: 1    2014    2015    2016  \\\n",
       "0   NaN                                           NaN     NaN     NaN     NaN   \n",
       "1   1.0                        Self-employed persons1  9358.0  9508.0  9604.0   \n",
       "2   2.0   Agriculture, forestry, fishing, and hunting   757.0   843.0   852.0   \n",
       "3   3.0                                        Farms2   680.0   760.0   771.0   \n",
       "4   4.0      Forestry, fishing and related activities    77.0    83.0    81.0   \n",
       "\n",
       "     2017    2018    2019    2020    2021  \n",
       "0     NaN     NaN     NaN     NaN     NaN  \n",
       "1  9525.0  9707.0  9539.0  9253.0  9956.0  \n",
       "2   790.0   766.0   741.0   741.0   737.0  \n",
       "3   711.0   684.0   664.0   669.0   669.0  \n",
       "4    79.0    82.0    77.0    72.0    68.0  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "US_business_df = pd.read_csv(\"data/us_small_bus.csv\")\n",
    "US_business_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see the first column 'Line' is unecessary so we can drop it. There are also rows that are all 0's. These will also be unecessary so we can drop those rows as well. We can also see that the second column is named 'Unnamed:1' which is not very informative. We can rename this column to 'industry'. Throughout the dataset, there are some strangely named entries such as \"Farms2\". Because the dataset is small, we can individually change the names of each of these entries. One last thing that is easy to overlook is that each entry in the \"Unnamed:1\" column (renamed to \"industry\") has leading white spaces. This will cause unecceasry issues later, so we can just remove all leading white space in each entry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "vscode": {
     "languageId": "scala"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>industry</th>\n",
       "      <th>2014</th>\n",
       "      <th>2015</th>\n",
       "      <th>2016</th>\n",
       "      <th>2017</th>\n",
       "      <th>2018</th>\n",
       "      <th>2019</th>\n",
       "      <th>2020</th>\n",
       "      <th>2021</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Self-employed persons</td>\n",
       "      <td>9358.0</td>\n",
       "      <td>9508.0</td>\n",
       "      <td>9604.0</td>\n",
       "      <td>9525.0</td>\n",
       "      <td>9707.0</td>\n",
       "      <td>9539.0</td>\n",
       "      <td>9253.0</td>\n",
       "      <td>9956.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Agriculture, forestry, fishing, and hunting</td>\n",
       "      <td>757.0</td>\n",
       "      <td>843.0</td>\n",
       "      <td>852.0</td>\n",
       "      <td>790.0</td>\n",
       "      <td>766.0</td>\n",
       "      <td>741.0</td>\n",
       "      <td>741.0</td>\n",
       "      <td>737.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Farms</td>\n",
       "      <td>680.0</td>\n",
       "      <td>760.0</td>\n",
       "      <td>771.0</td>\n",
       "      <td>711.0</td>\n",
       "      <td>684.0</td>\n",
       "      <td>664.0</td>\n",
       "      <td>669.0</td>\n",
       "      <td>669.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Forestry, fishing and related activities</td>\n",
       "      <td>77.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>68.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Mining</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      industry    2014    2015    2016  \\\n",
       "1                        Self-employed persons  9358.0  9508.0  9604.0   \n",
       "2  Agriculture, forestry, fishing, and hunting   757.0   843.0   852.0   \n",
       "3                                        Farms   680.0   760.0   771.0   \n",
       "4     Forestry, fishing and related activities    77.0    83.0    81.0   \n",
       "5                                       Mining    20.0    20.0    17.0   \n",
       "\n",
       "     2017    2018    2019    2020    2021  \n",
       "1  9525.0  9707.0  9539.0  9253.0  9956.0  \n",
       "2   790.0   766.0   741.0   741.0   737.0  \n",
       "3   711.0   684.0   664.0   669.0   669.0  \n",
       "4    79.0    82.0    77.0    72.0    68.0  \n",
       "5    11.0     9.0    14.0    10.0    13.0  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#drop rows that are all 0's\n",
    "US_business_df = US_business_df.drop([0,6])\n",
    "\n",
    "#drop column 'Line' because it is not necessary\n",
    "US_business_df = US_business_df.drop(columns=['Line'])\n",
    "\n",
    "#rename the variables of two different cells\n",
    "US_business_df.iloc[0,0] = \"Self-employed persons\"\n",
    "US_business_df.iloc[2,0] = \"Farms\"\n",
    "US_business_df.iloc[14,0] = \"Professional and business services\"\n",
    "\n",
    "#rename first column\n",
    "US_business_df.rename(columns={'Unnamed: 1': 'industry'}, inplace=True)\n",
    "\n",
    "#clean up the leading white spaces in the industry column\n",
    "num_industries = len(US_business_df)\n",
    "for i in range(num_industries):\n",
    "    cleaned_word = US_business_df.iloc[i,0].strip()\n",
    "    US_business_df.iloc[i,0] = cleaned_word\n",
    "\n",
    "US_business_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "vscode": {
     "languageId": "scala"
    }
   },
   "outputs": [],
   "source": [
    "#export as csv\n",
    "US_business_df.to_csv('cleaned_data/us_small_bus_updated.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
